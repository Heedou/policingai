laworder_yanolja+EEVE-Korean-Instruct-10.8B-v1.0_Task1:
  wandb:
    api_key: fec6d9b1f4fd39ff3d00d863cef56c9420b07745
    project_name: Beluga_Benchmark
    group_name: 241011_main_experiment
    session_name: laworder_yanolja+EEVE-Korean-Instruct-10.8B-v1.0_Task1
  path:
    dataset: data
    checkpoint: checkpoint
    template: /laworder/template/
    result: /laworder/result/
  dataprep:
    raw_dataset: task1
    raw_dataset_train: task1_v1.8_train
    raw_dataset_dev: task1_v1.8_dev
    finetuning_dataset: finetuning
    subsample: 1.0
  finetune:
    device: cuda
    report_to: wandb
    llm_backbone: yanolja/EEVE-Korean-Instruct-10.8B-v1.0
    lora:
      enabled: true
      qlora: true
      r: 8
      alpha: 32
      dropout: 0.05
      bias: none
      task_type: CAUSAL_LM
    per_device_train_batch_size: 4
    gradient_accumulation_steps: 1
    num_train_epochs: 5
    learning_rate: 0.0001
    fp16: true
    logging_steps: 1000
    output_dir: null
    optim: paged_adamw_8bit